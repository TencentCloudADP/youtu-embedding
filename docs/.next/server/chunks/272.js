"use strict";exports.id=272,exports.ids=[272],exports.modules={65272:(a,b,c)=>{c.d(b,{Fm:()=>x,sP:()=>w});var d={};c.r(d),c.d(d,{_markdown:()=>g,default:()=>m,extractedReferences:()=>i,frontmatter:()=>h,structuredData:()=>j,toc:()=>k});var e={};c.r(e),c.d(e,{_markdown:()=>o,default:()=>u,extractedReferences:()=>q,frontmatter:()=>p,structuredData:()=>r,toc:()=>s});var f=c(75338);let g='## Code Block\n\n```js\nconsole.log(\'Hello World\');\n```\n\n## Cards\n\n<Cards>\n  <Card title="Learn more about Next.js" href="https://nextjs.org/docs" />\n\n  <Card title="Learn more about Fumadocs" href="https://fumadocs.vercel.app" />\n</Cards>\n',h={title:"Components",description:"Components"},i=[],j={contents:[],headings:[{id:"code-block",content:"Code Block"},{id:"cards",content:"Cards"}]},k=[{depth:2,url:"#code-block",title:(0,f.jsx)(f.Fragment,{children:"Code Block"})},{depth:2,url:"#cards",title:(0,f.jsx)(f.Fragment,{children:"Cards"})}];function l(a){let b={code:"code",h2:"h2",pre:"pre",span:"span",...a.components},{Card:c,Cards:d}=b;return c||n("Card",!0),d||n("Cards",!0),(0,f.jsxs)(f.Fragment,{children:[(0,f.jsx)(b.h2,{id:"code-block",children:"Code Block"}),"\n",(0,f.jsx)(f.Fragment,{children:(0,f.jsx)(b.pre,{className:"shiki shiki-themes github-light github-dark",style:{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},tabIndex:"0",icon:'<svg viewBox="0 0 24 24"><path d="M0 0h24v24H0V0zm22.034 18.276c-.175-1.095-.888-2.015-3.003-2.873-.736-.345-1.554-.585-1.797-1.14-.091-.33-.105-.51-.046-.705.15-.646.915-.84 1.515-.66.39.12.75.42.976.9 1.034-.676 1.034-.676 1.755-1.125-.27-.42-.404-.601-.586-.78-.63-.705-1.469-1.065-2.834-1.034l-.705.089c-.676.165-1.32.525-1.71 1.005-1.14 1.291-.811 3.541.569 4.471 1.365 1.02 3.361 1.244 3.616 2.205.24 1.17-.87 1.545-1.966 1.41-.811-.18-1.26-.586-1.755-1.336l-1.83 1.051c.21.48.45.689.81 1.109 1.74 1.756 6.09 1.666 6.871-1.004.029-.09.24-.705.074-1.65l.046.067zm-8.983-7.245h-2.248c0 1.938-.009 3.864-.009 5.805 0 1.232.063 2.363-.138 2.711-.33.689-1.18.601-1.566.48-.396-.196-.597-.466-.83-.855-.063-.105-.11-.196-.127-.196l-1.825 1.125c.305.63.75 1.172 1.324 1.517.855.51 2.004.675 3.207.405.783-.226 1.458-.691 1.811-1.411.51-.93.402-2.07.397-3.346.012-2.054 0-4.109 0-6.179l.004-.056z" fill="currentColor" /></svg>',children:(0,f.jsx)(b.code,{children:(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:"console."}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#6F42C1","--shiki-dark":"#B392F0"},children:"log"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:"("}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:"'Hello World'"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:");"})]})})})}),"\n",(0,f.jsx)(b.h2,{id:"cards",children:"Cards"}),"\n",(0,f.jsxs)(d,{children:[(0,f.jsx)(c,{title:"Learn more about Next.js",href:"https://nextjs.org/docs"}),(0,f.jsx)(c,{title:"Learn more about Fumadocs",href:"https://fumadocs.vercel.app"})]})]})}function m(a={}){let{wrapper:b}=a.components||{};return b?(0,f.jsx)(b,{...a,children:(0,f.jsx)(l,{...a})}):l(a)}function n(a,b){throw Error("Expected "+(b?"component":"object")+" `"+a+"` to be defined: you likely forgot to import, pass, or provide it.")}let o='## \uD83C\uDFAF Brief Introduction\n\n**Youtu-Embedding** is an industry-leading, general-purpose text representation model developed by Tencent Youtu Lab. It demonstrates state-of-the-art performance across a wide range of natural language processing tasks, including Information Retrieval (IR), Semantic Textual Similarity (STS), Clustering, Reranking, and Classification.\n\nThe core advantages of Youtu-Embedding can be summarized as follows:\n\n* **\uD83C\uDFC6 State-of-the-Art Performance**: Achieved a top score of **77.46** on the authoritative Chinese text embedding benchmark CMTEB (as of Sep 2025), proving its powerful representation capabilities.\n* **\uD83E\uDDE0 Sophisticated Three-Stage Training:** We pioneered a "LLM-based Pre-training → Weakly-supervised Alignment → Collaborative-Discriminative Fine-tuning" pipeline, which systematically distills the broad knowledge of large language models into the specialized discriminative power required for embedding tasks.\n* **⭐ Innovative Fine-tuning Framework**: We designed a unique Collaborative-Discriminative Fine-tuning Framework that effectively resolves the "negative transfer" problem in multi-task learning through a unified data format, task-differentiated loss functions, and a dynamic single-task sampling mechanism. (This framework has been verified on a variety of basic encoders to ensure its versatility and effectiveness.)\n* **\uD83D\uDEE0️ Meticulous Data Engineering**: We combined high-quality, LLM-based data synthesis with efficient hard negative mining strategies to provide the most robust data foundation for model training.\n\n## \uD83E\uDD17 Model Download\n\nWe have released our first model version on Hugging Face. It is a 2 billion (2B) parameter model designed for general-purpose semantic representation.\n\n| Model              | Parameters | Dimensions | Sequence Length | Hugging Face                                                                        |\n| :----------------- | :--------: | :--------: | :-------------: | :---------------------------------------------------------------------------------- |\n| Youtu-Embedding-V1 |     2B     |    2048    |        8K       | [Youtu-RAG/Youtu-Embedding-V1](https://huggingface.co/Youtu-RAG/Youtu-Embedding-V1) |\n\n<a id="quickstart" />\n\n## \uD83D\uDE80 Quickly Start Inference\n\nYou can generate embeddings in two ways: via our official API for ease of use or by running the model locally for full control.\n\n### Option 1: ☁️ Using the Official API\n\n**\uD83D\uDCE6 Install the SDK**\n\n```bash\npip install --upgrade tencentcloud-sdk-python\n```\n\n* **API Guide**: For details on authentication and endpoints, see the [Tencent Cloud API Documentation](https://cloud.tencent.com/document/product/1772/115343).\n* **SDK Reference**: For more on the SDK, refer to the [SDK Installation Guide](https://cloud.tencent.com/document/sdk).\n\n**⚙️ Usage**\n\n* Please see the script in [`usage/tencent_cloud_api.py`](usage/tencent_cloud_api.py).\n\n### Option 2: \uD83D\uDCBB Locally with Self-Hosted Inference\n\nRunning the model on your own machine gives you full control, making it perfect for offline use, customization, or when data privacy is a priority. Here are a few popular ways to get started.\n\n#### 1. Using the Custom `LLMEmbeddingModel` Class\n\nFor a more specialized implementation or to see our direct wrapper, you can use the `LLMEmbeddingModel` class.\n\n* See the complete example script here: [`usage/infer_llm_embedding.py`](usage/infer_llm_embedding.py).\n\n#### 2. Using `sentence-transformers`\n\n**\uD83D\uDCE6 Installation**\n\n```bash\npip install sentence-transformers==5.1.0\n```\n\n**⚙️ Usage**\n\n```python\nfrom sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer("model_id")\nqueries = ["What\'s the weather like?"]\npassages = [\n    \'The weather is lovely today.\',\n    "It\'s so sunny outside!",\n    \'He drove to the stadium.\'\n]\nqueries_embeddings = model.encode_query(queries)\npassages_embeddings = model.encode_document(passages)\n\nsimilarities = model.similarity(queries_embeddings, passages_embeddings)\nprint(similarities)\n```\n\n#### 3. Using `LangChain` \uD83E\uDD9C\n\nEasily integrate the model into your **LangChain** applications, such as RAG pipelines.\n\n**\uD83D\uDCE6 Installation**\n\n```bash\npip install langchain==0.3.27 langchain-community==0.3.29 langchain-huggingface==0.3.1 sentence-transformers==5.1.0 faiss-cpu==1.11.0\n```\n\n**⚙️ Usage**\n\n* See this example: [`usage/langchain_embedding.py`](usage/langchain_embedding.py)\n\n#### 4. Using `LlamaIndex` \uD83E\uDD99\n\nThis is perfect for integrating the model into your **LlamaIndex** search and retrieval systems.\n\n**\uD83D\uDCE6 Installation**\n\n```bash\npip install llama-index==0.14.2 llama-index-embeddings-huggingface==0.6.1 sentence-transformers==5.1.0 llama-index-vector-stores-faiss==0.5.1\n```\n\n**⚙️ Usage**\n\n* See this example: [`usage/llamaindex_embedding.py`](usage/llamaindex_embedding.py)\n\n## \uD83D\uDCA1 Fine-tuning Framework\n\nWe provide our novel **Collaborative-Discriminative Fine-tuning Framework**, designed to overcome the challenges of jointly optimizing different text embedding tasks. By systematically decoupling tasks, we introduce several key innovations to achieve highly efficient unified representation learning.\n\n**\uD83C\uDF10 1. Unified & Extensible Data Format**\n\nOur unified data structure seamlessly handles heterogeneous data from IR, STS, classification, and reranking tasks, offering excellent extensibility for incorporating new tasks in the future.\n\n**\uD83C\uDFAF 2. Task-Differentiated Loss Functions**\n\nWe moved beyond a "one-size-fits-all" loss function and designed specialized optimization objectives for different tasks.\n\n* **For IR (Information Retrieval) tasks**: We use a powerful InfoNCE contrastive loss that supports multiple positives, hard negatives, and in-batch cross-device negative sampling for superior discriminative ability.\n\n* **For STS (Semantic Textual Similarity) tasks**: We go beyond simple contrastive learning by adopting ranking-aware objectives (e.g., Pearson loss, KL divergence loss L\\_RankKL) to directly optimize for ranking consistency.\n\n**\uD83D\uDD04 3. Dynamic Single-Task Sampling**\n\nTo prevent gradient interference from mixed-task batches, we implemented a custom dynamic sampler. It ensures that within a single training iteration, all GPUs process non-overlapping shards of the same dataset, providing the model with a pure and stable gradient signal.\n\n<a id="train" />\n\n### \uD83D\uDEE0️ How to Train\n\nThe code for our training framework is located in the [`training/`](training/) directory.\n\n#### 1. Installation\n\nClone the repository and install the required dependencies:\n\n```bash\ngit clone https://github.com/Tencent/CoDiEmb.git\ncd CoDiEmb\npip install -r requirements.txt\n```\n\n#### 2. Training\n\n```bash\ncd scripts\nbash train_youtuemb.sh\n```\n\n#### 3. Evaluation\n\nThe code for reproducing the following results is available in `evaluation/`.\n\n## \uD83D\uDCCA CMTEB\n\nYoutu-Embedding demonstrates superior performance across all seven task categories on the CMTEB benchmark and achieves the highest overall average score. We present the results of the latest version of the model as follows:\n\n| Model                       | Mean(Task) | Mean(Type) | Class. | Clust. | Pair Class. | Rerank. | Retr. |  STS  |\n| :-------------------------- | :--------- | :--------- | :----: | :----: | :---------: | :-----: | :---: | :---: |\n| gte-Qwen2-1.5B-instruct     | 67.12      | 67.79      |  72.53 |  54.61 |    79.50    |  68.21  | 71.86 | 60.05 |\n| bge-multilingual-gemma2     | 67.64      | 68.52      |  75.31 |  59.30 |    86.67    |  68.28  | 73.73 | 55.19 |\n| ritrieve\\_zh\\_v1            | 72.71      | 73.85      |  76.88 |  66.50 |    85.98    |  72.86  | 76.97 | 63.92 |\n| Qwen3-Embedding-4B          | 72.27      | 73.51      |  75.46 |  77.89 |    83.34    |  66.05  | 77.03 | 61.26 |\n| Qwen3-Embedding-8B          | 73.84      | 75.00      |  76.97 |  80.08 |    84.23    |  66.99  | 78.21 | 63.53 |\n| Conan-embedding-v2          | 74.24      | 75.99      |  76.47 |  68.84 |    92.44    |  74.41  | 78.31 | 65.48 |\n| Seed1.6-embedding           | 75.63      | 76.68      |  77.98 |  73.11 |    88.71    |  71.65  | 79.69 | 68.94 |\n| QZhou-Embedding             | 76.99      | 78.58      |  79.99 |  70.91 |    95.07    |  74.85  | 78.80 | 71.89 |\n| **Youtu-Embedding-V1-0917** | **77.60**  | **78.85**  |  78.04 |  79.67 |    89.69    |  73.85  | 80.95 | 70.91 |\n\n## \uD83C\uDF89 Citation\n\nIf you find our work useful in your research, please consider citing our paper:\n',p={title:"Youtu-Embedding Docs",description:"Introduce Youtu-Embedding"},q=[{href:"https://huggingface.co/Youtu-RAG/Youtu-Embedding-V1"},{href:"https://cloud.tencent.com/document/product/1772/115343"},{href:"https://cloud.tencent.com/document/sdk"},{href:"usage/tencent_cloud_api.py"},{href:"usage/infer_llm_embedding.py"},{href:"usage/langchain_embedding.py"},{href:"usage/llamaindex_embedding.py"},{href:"training/"}],r={contents:[{heading:"-brief-introduction",content:"Youtu-Embedding is an industry-leading, general-purpose text representation model developed by Tencent Youtu Lab. It demonstrates state-of-the-art performance across a wide range of natural language processing tasks, including Information Retrieval (IR), Semantic Textual Similarity (STS), Clustering, Reranking, and Classification."},{heading:"-brief-introduction",content:"The core advantages of Youtu-Embedding can be summarized as follows:"},{heading:"-brief-introduction",content:"\uD83C\uDFC6 State-of-the-Art Performance: Achieved a top score of 77.46 on the authoritative Chinese text embedding benchmark CMTEB (as of Sep 2025), proving its powerful representation capabilities."},{heading:"-brief-introduction",content:'\uD83E\uDDE0 Sophisticated Three-Stage Training: We pioneered a "LLM-based Pre-training → Weakly-supervised Alignment → Collaborative-Discriminative Fine-tuning" pipeline, which systematically distills the broad knowledge of large language models into the specialized discriminative power required for embedding tasks.'},{heading:"-brief-introduction",content:'⭐ Innovative Fine-tuning Framework: We designed a unique Collaborative-Discriminative Fine-tuning Framework that effectively resolves the "negative transfer" problem in multi-task learning through a unified data format, task-differentiated loss functions, and a dynamic single-task sampling mechanism. (This framework has been verified on a variety of basic encoders to ensure its versatility and effectiveness.)'},{heading:"-brief-introduction",content:"\uD83D\uDEE0️ Meticulous Data Engineering: We combined high-quality, LLM-based data synthesis with efficient hard negative mining strategies to provide the most robust data foundation for model training."},{heading:"-model-download",content:"We have released our first model version on Hugging Face. It is a 2 billion (2B) parameter model designed for general-purpose semantic representation."},{heading:"-model-download",content:"Model"},{heading:"-model-download",content:"Parameters"},{heading:"-model-download",content:"Dimensions"},{heading:"-model-download",content:"Sequence Length"},{heading:"-model-download",content:"Hugging Face"},{heading:"-model-download",content:"Youtu-Embedding-V1"},{heading:"-model-download",content:"2B"},{heading:"-model-download",content:"2048"},{heading:"-model-download",content:"8K"},{heading:"-model-download",content:"Youtu-RAG/Youtu-Embedding-V1"},{heading:"-quickly-start-inference",content:"You can generate embeddings in two ways: via our official API for ease of use or by running the model locally for full control."},{heading:"option-1-️-using-the-official-api",content:"\uD83D\uDCE6 Install the SDK"},{heading:"option-1-️-using-the-official-api",content:"API Guide: For details on authentication and endpoints, see the Tencent Cloud API Documentation."},{heading:"option-1-️-using-the-official-api",content:"SDK Reference: For more on the SDK, refer to the SDK Installation Guide."},{heading:"option-1-️-using-the-official-api",content:"⚙️ Usage"},{heading:"option-1-️-using-the-official-api",content:"Please see the script in usage/tencent_cloud_api.py."},{heading:"option-2--locally-with-self-hosted-inference",content:"Running the model on your own machine gives you full control, making it perfect for offline use, customization, or when data privacy is a priority. Here are a few popular ways to get started."},{heading:"1-using-the-custom-llmembeddingmodel-class",content:"For a more specialized implementation or to see our direct wrapper, you can use the LLMEmbeddingModel class."},{heading:"1-using-the-custom-llmembeddingmodel-class",content:"See the complete example script here: usage/infer_llm_embedding.py."},{heading:"2-using-sentence-transformers",content:"\uD83D\uDCE6 Installation"},{heading:"2-using-sentence-transformers",content:"⚙️ Usage"},{heading:"3-using-langchain-",content:"Easily integrate the model into your LangChain applications, such as RAG pipelines."},{heading:"3-using-langchain-",content:"\uD83D\uDCE6 Installation"},{heading:"3-using-langchain-",content:"⚙️ Usage"},{heading:"3-using-langchain-",content:"See this example: usage/langchain_embedding.py"},{heading:"4-using-llamaindex-",content:"This is perfect for integrating the model into your LlamaIndex search and retrieval systems."},{heading:"4-using-llamaindex-",content:"\uD83D\uDCE6 Installation"},{heading:"4-using-llamaindex-",content:"⚙️ Usage"},{heading:"4-using-llamaindex-",content:"See this example: usage/llamaindex_embedding.py"},{heading:"-fine-tuning-framework",content:"We provide our novel Collaborative-Discriminative Fine-tuning Framework, designed to overcome the challenges of jointly optimizing different text embedding tasks. By systematically decoupling tasks, we introduce several key innovations to achieve highly efficient unified representation learning."},{heading:"-fine-tuning-framework",content:"\uD83C\uDF10 1. Unified & Extensible Data Format"},{heading:"-fine-tuning-framework",content:"Our unified data structure seamlessly handles heterogeneous data from IR, STS, classification, and reranking tasks, offering excellent extensibility for incorporating new tasks in the future."},{heading:"-fine-tuning-framework",content:"\uD83C\uDFAF 2. Task-Differentiated Loss Functions"},{heading:"-fine-tuning-framework",content:'We moved beyond a "one-size-fits-all" loss function and designed specialized optimization objectives for different tasks.'},{heading:"-fine-tuning-framework",content:"For IR (Information Retrieval) tasks: We use a powerful InfoNCE contrastive loss that supports multiple positives, hard negatives, and in-batch cross-device negative sampling for superior discriminative ability."},{heading:"-fine-tuning-framework",content:"For STS (Semantic Textual Similarity) tasks: We go beyond simple contrastive learning by adopting ranking-aware objectives (e.g., Pearson loss, KL divergence loss L_RankKL) to directly optimize for ranking consistency."},{heading:"-fine-tuning-framework",content:"\uD83D\uDD04 3. Dynamic Single-Task Sampling"},{heading:"-fine-tuning-framework",content:"To prevent gradient interference from mixed-task batches, we implemented a custom dynamic sampler. It ensures that within a single training iteration, all GPUs process non-overlapping shards of the same dataset, providing the model with a pure and stable gradient signal."},{heading:"️-how-to-train",content:"The code for our training framework is located in the training/ directory."},{heading:"1-installation",content:"Clone the repository and install the required dependencies:"},{heading:"3-evaluation",content:"The code for reproducing the following results is available in evaluation/."},{heading:"-cmteb",content:"Youtu-Embedding demonstrates superior performance across all seven task categories on the CMTEB benchmark and achieves the highest overall average score. We present the results of the latest version of the model as follows:"},{heading:"-cmteb",content:"Model"},{heading:"-cmteb",content:"Mean(Task)"},{heading:"-cmteb",content:"Mean(Type)"},{heading:"-cmteb",content:"Class."},{heading:"-cmteb",content:"Clust."},{heading:"-cmteb",content:"Pair Class."},{heading:"-cmteb",content:"Rerank."},{heading:"-cmteb",content:"Retr."},{heading:"-cmteb",content:"STS"},{heading:"-cmteb",content:"gte-Qwen2-1.5B-instruct"},{heading:"-cmteb",content:"67.12"},{heading:"-cmteb",content:"67.79"},{heading:"-cmteb",content:"72.53"},{heading:"-cmteb",content:"54.61"},{heading:"-cmteb",content:"79.50"},{heading:"-cmteb",content:"68.21"},{heading:"-cmteb",content:"71.86"},{heading:"-cmteb",content:"60.05"},{heading:"-cmteb",content:"bge-multilingual-gemma2"},{heading:"-cmteb",content:"67.64"},{heading:"-cmteb",content:"68.52"},{heading:"-cmteb",content:"75.31"},{heading:"-cmteb",content:"59.30"},{heading:"-cmteb",content:"86.67"},{heading:"-cmteb",content:"68.28"},{heading:"-cmteb",content:"73.73"},{heading:"-cmteb",content:"55.19"},{heading:"-cmteb",content:"ritrieve_zh_v1"},{heading:"-cmteb",content:"72.71"},{heading:"-cmteb",content:"73.85"},{heading:"-cmteb",content:"76.88"},{heading:"-cmteb",content:"66.50"},{heading:"-cmteb",content:"85.98"},{heading:"-cmteb",content:"72.86"},{heading:"-cmteb",content:"76.97"},{heading:"-cmteb",content:"63.92"},{heading:"-cmteb",content:"Qwen3-Embedding-4B"},{heading:"-cmteb",content:"72.27"},{heading:"-cmteb",content:"73.51"},{heading:"-cmteb",content:"75.46"},{heading:"-cmteb",content:"77.89"},{heading:"-cmteb",content:"83.34"},{heading:"-cmteb",content:"66.05"},{heading:"-cmteb",content:"77.03"},{heading:"-cmteb",content:"61.26"},{heading:"-cmteb",content:"Qwen3-Embedding-8B"},{heading:"-cmteb",content:"73.84"},{heading:"-cmteb",content:"75.00"},{heading:"-cmteb",content:"76.97"},{heading:"-cmteb",content:"80.08"},{heading:"-cmteb",content:"84.23"},{heading:"-cmteb",content:"66.99"},{heading:"-cmteb",content:"78.21"},{heading:"-cmteb",content:"63.53"},{heading:"-cmteb",content:"Conan-embedding-v2"},{heading:"-cmteb",content:"74.24"},{heading:"-cmteb",content:"75.99"},{heading:"-cmteb",content:"76.47"},{heading:"-cmteb",content:"68.84"},{heading:"-cmteb",content:"92.44"},{heading:"-cmteb",content:"74.41"},{heading:"-cmteb",content:"78.31"},{heading:"-cmteb",content:"65.48"},{heading:"-cmteb",content:"Seed1.6-embedding"},{heading:"-cmteb",content:"75.63"},{heading:"-cmteb",content:"76.68"},{heading:"-cmteb",content:"77.98"},{heading:"-cmteb",content:"73.11"},{heading:"-cmteb",content:"88.71"},{heading:"-cmteb",content:"71.65"},{heading:"-cmteb",content:"79.69"},{heading:"-cmteb",content:"68.94"},{heading:"-cmteb",content:"QZhou-Embedding"},{heading:"-cmteb",content:"76.99"},{heading:"-cmteb",content:"78.58"},{heading:"-cmteb",content:"79.99"},{heading:"-cmteb",content:"70.91"},{heading:"-cmteb",content:"95.07"},{heading:"-cmteb",content:"74.85"},{heading:"-cmteb",content:"78.80"},{heading:"-cmteb",content:"71.89"},{heading:"-cmteb",content:"Youtu-Embedding-V1-0917"},{heading:"-cmteb",content:"77.60"},{heading:"-cmteb",content:"78.85"},{heading:"-cmteb",content:"78.04"},{heading:"-cmteb",content:"79.67"},{heading:"-cmteb",content:"89.69"},{heading:"-cmteb",content:"73.85"},{heading:"-cmteb",content:"80.95"},{heading:"-cmteb",content:"70.91"},{heading:"-citation",content:"If you find our work useful in your research, please consider citing our paper:"}],headings:[{id:"-brief-introduction",content:"\uD83C\uDFAF Brief Introduction"},{id:"-model-download",content:"\uD83E\uDD17 Model Download"},{id:"-quickly-start-inference",content:"\uD83D\uDE80 Quickly Start Inference"},{id:"option-1-️-using-the-official-api",content:"Option 1: ☁️ Using the Official API"},{id:"option-2--locally-with-self-hosted-inference",content:"Option 2: \uD83D\uDCBB Locally with Self-Hosted Inference"},{id:"1-using-the-custom-llmembeddingmodel-class",content:"1. Using the Custom LLMEmbeddingModel Class"},{id:"2-using-sentence-transformers",content:"2. Using sentence-transformers"},{id:"3-using-langchain-",content:"3. Using LangChain \uD83E\uDD9C"},{id:"4-using-llamaindex-",content:"4. Using LlamaIndex \uD83E\uDD99"},{id:"-fine-tuning-framework",content:"\uD83D\uDCA1 Fine-tuning Framework"},{id:"️-how-to-train",content:"\uD83D\uDEE0️ How to Train"},{id:"1-installation",content:"1. Installation"},{id:"2-training",content:"2. Training"},{id:"3-evaluation",content:"3. Evaluation"},{id:"-cmteb",content:"\uD83D\uDCCA CMTEB"},{id:"-citation",content:"\uD83C\uDF89 Citation"}]},s=[{depth:2,url:"#-brief-introduction",title:(0,f.jsx)(f.Fragment,{children:"\uD83C\uDFAF Brief Introduction"})},{depth:2,url:"#-model-download",title:(0,f.jsx)(f.Fragment,{children:"\uD83E\uDD17 Model Download"})},{depth:2,url:"#-quickly-start-inference",title:(0,f.jsx)(f.Fragment,{children:"\uD83D\uDE80 Quickly Start Inference"})},{depth:3,url:"#option-1-️-using-the-official-api",title:(0,f.jsx)(f.Fragment,{children:"Option 1: ☁️ Using the Official API"})},{depth:3,url:"#option-2--locally-with-self-hosted-inference",title:(0,f.jsx)(f.Fragment,{children:"Option 2: \uD83D\uDCBB Locally with Self-Hosted Inference"})},{depth:4,url:"#1-using-the-custom-llmembeddingmodel-class",title:(0,f.jsxs)(f.Fragment,{children:["1. Using the Custom ",(0,f.jsx)("code",{children:"LLMEmbeddingModel"})," Class"]})},{depth:4,url:"#2-using-sentence-transformers",title:(0,f.jsxs)(f.Fragment,{children:["2. Using ",(0,f.jsx)("code",{children:"sentence-transformers"})]})},{depth:4,url:"#3-using-langchain-",title:(0,f.jsxs)(f.Fragment,{children:["3. Using ",(0,f.jsx)("code",{children:"LangChain"})," \uD83E\uDD9C"]})},{depth:4,url:"#4-using-llamaindex-",title:(0,f.jsxs)(f.Fragment,{children:["4. Using ",(0,f.jsx)("code",{children:"LlamaIndex"})," \uD83E\uDD99"]})},{depth:2,url:"#-fine-tuning-framework",title:(0,f.jsx)(f.Fragment,{children:"\uD83D\uDCA1 Fine-tuning Framework"})},{depth:3,url:"#️-how-to-train",title:(0,f.jsx)(f.Fragment,{children:"\uD83D\uDEE0️ How to Train"})},{depth:4,url:"#1-installation",title:(0,f.jsx)(f.Fragment,{children:"1. Installation"})},{depth:4,url:"#2-training",title:(0,f.jsx)(f.Fragment,{children:"2. Training"})},{depth:4,url:"#3-evaluation",title:(0,f.jsx)(f.Fragment,{children:"3. Evaluation"})},{depth:2,url:"#-cmteb",title:(0,f.jsx)(f.Fragment,{children:"\uD83D\uDCCA CMTEB"})},{depth:2,url:"#-citation",title:(0,f.jsx)(f.Fragment,{children:"\uD83C\uDF89 Citation"})}];function t(a){let b={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",pre:"pre",span:"span",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...a.components};return(0,f.jsxs)(f.Fragment,{children:[(0,f.jsx)(b.h2,{id:"-brief-introduction",children:"\uD83C\uDFAF Brief Introduction"}),"\n",(0,f.jsxs)(b.p,{children:[(0,f.jsx)(b.strong,{children:"Youtu-Embedding"})," is an industry-leading, general-purpose text representation model developed by Tencent Youtu Lab. It demonstrates state-of-the-art performance across a wide range of natural language processing tasks, including Information Retrieval (IR), Semantic Textual Similarity (STS), Clustering, Reranking, and Classification."]}),"\n",(0,f.jsx)(b.p,{children:"The core advantages of Youtu-Embedding can be summarized as follows:"}),"\n",(0,f.jsxs)(b.ul,{children:["\n",(0,f.jsxs)(b.li,{children:[(0,f.jsx)(b.strong,{children:"\uD83C\uDFC6 State-of-the-Art Performance"}),": Achieved a top score of ",(0,f.jsx)(b.strong,{children:"77.46"})," on the authoritative Chinese text embedding benchmark CMTEB (as of Sep 2025), proving its powerful representation capabilities."]}),"\n",(0,f.jsxs)(b.li,{children:[(0,f.jsx)(b.strong,{children:"\uD83E\uDDE0 Sophisticated Three-Stage Training:"}),' We pioneered a "LLM-based Pre-training → Weakly-supervised Alignment → Collaborative-Discriminative Fine-tuning" pipeline, which systematically distills the broad knowledge of large language models into the specialized discriminative power required for embedding tasks.']}),"\n",(0,f.jsxs)(b.li,{children:[(0,f.jsx)(b.strong,{children:"⭐ Innovative Fine-tuning Framework"}),': We designed a unique Collaborative-Discriminative Fine-tuning Framework that effectively resolves the "negative transfer" problem in multi-task learning through a unified data format, task-differentiated loss functions, and a dynamic single-task sampling mechanism. (This framework has been verified on a variety of basic encoders to ensure its versatility and effectiveness.)']}),"\n",(0,f.jsxs)(b.li,{children:[(0,f.jsx)(b.strong,{children:"\uD83D\uDEE0️ Meticulous Data Engineering"}),": We combined high-quality, LLM-based data synthesis with efficient hard negative mining strategies to provide the most robust data foundation for model training."]}),"\n"]}),"\n",(0,f.jsx)(b.h2,{id:"-model-download",children:"\uD83E\uDD17 Model Download"}),"\n",(0,f.jsx)(b.p,{children:"We have released our first model version on Hugging Face. It is a 2 billion (2B) parameter model designed for general-purpose semantic representation."}),"\n",(0,f.jsxs)(b.table,{children:[(0,f.jsx)(b.thead,{children:(0,f.jsxs)(b.tr,{children:[(0,f.jsx)(b.th,{style:{textAlign:"left"},children:"Model"}),(0,f.jsx)(b.th,{style:{textAlign:"center"},children:"Parameters"}),(0,f.jsx)(b.th,{style:{textAlign:"center"},children:"Dimensions"}),(0,f.jsx)(b.th,{style:{textAlign:"center"},children:"Sequence Length"}),(0,f.jsx)(b.th,{style:{textAlign:"left"},children:"Hugging Face"})]})}),(0,f.jsx)(b.tbody,{children:(0,f.jsxs)(b.tr,{children:[(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"Youtu-Embedding-V1"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"2B"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"2048"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"8K"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:(0,f.jsx)(b.a,{href:"https://huggingface.co/Youtu-RAG/Youtu-Embedding-V1",children:"Youtu-RAG/Youtu-Embedding-V1"})})]})})]}),"\n",(0,f.jsx)("a",{id:"quickstart"}),"\n",(0,f.jsx)(b.h2,{id:"-quickly-start-inference",children:"\uD83D\uDE80 Quickly Start Inference"}),"\n",(0,f.jsx)(b.p,{children:"You can generate embeddings in two ways: via our official API for ease of use or by running the model locally for full control."}),"\n",(0,f.jsx)(b.h3,{id:"option-1-️-using-the-official-api",children:"Option 1: ☁️ Using the Official API"}),"\n",(0,f.jsx)(b.p,{children:(0,f.jsx)(b.strong,{children:"\uD83D\uDCE6 Install the SDK"})}),"\n",(0,f.jsx)(f.Fragment,{children:(0,f.jsx)(b.pre,{className:"shiki shiki-themes github-light github-dark",style:{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},tabIndex:"0",icon:'<svg viewBox="0 0 24 24"><path d="m 4,4 a 1,1 0 0 0 -0.7070312,0.2929687 1,1 0 0 0 0,1.4140625 L 8.5859375,11 3.2929688,16.292969 a 1,1 0 0 0 0,1.414062 1,1 0 0 0 1.4140624,0 l 5.9999998,-6 a 1.0001,1.0001 0 0 0 0,-1.414062 L 4.7070312,4.2929687 A 1,1 0 0 0 4,4 Z m 8,14 a 1,1 0 0 0 -1,1 1,1 0 0 0 1,1 h 8 a 1,1 0 0 0 1,-1 1,1 0 0 0 -1,-1 z" fill="currentColor" /></svg>',children:(0,f.jsx)(b.code,{children:(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#6F42C1","--shiki-dark":"#B392F0"},children:"pip"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" install"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},children:" --upgrade"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" tencentcloud-sdk-python"})]})})})}),"\n",(0,f.jsxs)(b.ul,{children:["\n",(0,f.jsxs)(b.li,{children:[(0,f.jsx)(b.strong,{children:"API Guide"}),": For details on authentication and endpoints, see the ",(0,f.jsx)(b.a,{href:"https://cloud.tencent.com/document/product/1772/115343",children:"Tencent Cloud API Documentation"}),"."]}),"\n",(0,f.jsxs)(b.li,{children:[(0,f.jsx)(b.strong,{children:"SDK Reference"}),": For more on the SDK, refer to the ",(0,f.jsx)(b.a,{href:"https://cloud.tencent.com/document/sdk",children:"SDK Installation Guide"}),"."]}),"\n"]}),"\n",(0,f.jsx)(b.p,{children:(0,f.jsx)(b.strong,{children:"⚙️ Usage"})}),"\n",(0,f.jsxs)(b.ul,{children:["\n",(0,f.jsxs)(b.li,{children:["Please see the script in ",(0,f.jsx)(b.a,{href:"usage/tencent_cloud_api.py",children:(0,f.jsx)(b.code,{children:"usage/tencent_cloud_api.py"})}),"."]}),"\n"]}),"\n",(0,f.jsx)(b.h3,{id:"option-2--locally-with-self-hosted-inference",children:"Option 2: \uD83D\uDCBB Locally with Self-Hosted Inference"}),"\n",(0,f.jsx)(b.p,{children:"Running the model on your own machine gives you full control, making it perfect for offline use, customization, or when data privacy is a priority. Here are a few popular ways to get started."}),"\n",(0,f.jsxs)(b.h4,{id:"1-using-the-custom-llmembeddingmodel-class",children:["1. Using the Custom ",(0,f.jsx)(b.code,{children:"LLMEmbeddingModel"})," Class"]}),"\n",(0,f.jsxs)(b.p,{children:["For a more specialized implementation or to see our direct wrapper, you can use the ",(0,f.jsx)(b.code,{children:"LLMEmbeddingModel"})," class."]}),"\n",(0,f.jsxs)(b.ul,{children:["\n",(0,f.jsxs)(b.li,{children:["See the complete example script here: ",(0,f.jsx)(b.a,{href:"usage/infer_llm_embedding.py",children:(0,f.jsx)(b.code,{children:"usage/infer_llm_embedding.py"})}),"."]}),"\n"]}),"\n",(0,f.jsxs)(b.h4,{id:"2-using-sentence-transformers",children:["2. Using ",(0,f.jsx)(b.code,{children:"sentence-transformers"})]}),"\n",(0,f.jsx)(b.p,{children:(0,f.jsx)(b.strong,{children:"\uD83D\uDCE6 Installation"})}),"\n",(0,f.jsx)(f.Fragment,{children:(0,f.jsx)(b.pre,{className:"shiki shiki-themes github-light github-dark",style:{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},tabIndex:"0",icon:'<svg viewBox="0 0 24 24"><path d="m 4,4 a 1,1 0 0 0 -0.7070312,0.2929687 1,1 0 0 0 0,1.4140625 L 8.5859375,11 3.2929688,16.292969 a 1,1 0 0 0 0,1.414062 1,1 0 0 0 1.4140624,0 l 5.9999998,-6 a 1.0001,1.0001 0 0 0 0,-1.414062 L 4.7070312,4.2929687 A 1,1 0 0 0 4,4 Z m 8,14 a 1,1 0 0 0 -1,1 1,1 0 0 0 1,1 h 8 a 1,1 0 0 0 1,-1 1,1 0 0 0 -1,-1 z" fill="currentColor" /></svg>',children:(0,f.jsx)(b.code,{children:(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#6F42C1","--shiki-dark":"#B392F0"},children:"pip"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" install"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" sentence-transformers=="}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},children:"5.1.0"})]})})})}),"\n",(0,f.jsx)(b.p,{children:(0,f.jsx)(b.strong,{children:"⚙️ Usage"})}),"\n",(0,f.jsx)(f.Fragment,{children:(0,f.jsx)(b.pre,{className:"shiki shiki-themes github-light github-dark",style:{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},tabIndex:"0",icon:'<svg viewBox="0 0 24 24"><path d="M14.25.18l.9.2.73.26.59.3.45.32.34.34.25.34.16.33.1.3.04.26.02.2-.01.13V8.5l-.05.63-.13.55-.21.46-.26.38-.3.31-.33.25-.35.19-.35.14-.33.1-.3.07-.26.04-.21.02H8.77l-.69.05-.59.14-.5.22-.41.27-.33.32-.27.35-.2.36-.15.37-.1.35-.07.32-.04.27-.02.21v3.06H3.17l-.21-.03-.28-.07-.32-.12-.35-.18-.36-.26-.36-.36-.35-.46-.32-.59-.28-.73-.21-.88-.14-1.05-.05-1.23.06-1.22.16-1.04.24-.87.32-.71.36-.57.4-.44.42-.33.42-.24.4-.16.36-.1.32-.05.24-.01h.16l.06.01h8.16v-.83H6.18l-.01-2.75-.02-.37.05-.34.11-.31.17-.28.25-.26.31-.23.38-.2.44-.18.51-.15.58-.12.64-.1.71-.06.77-.04.84-.02 1.27.05zm-6.3 1.98l-.23.33-.08.41.08.41.23.34.33.22.41.09.41-.09.33-.22.23-.34.08-.41-.08-.41-.23-.33-.33-.22-.41-.09-.41.09zm13.09 3.95l.28.06.32.12.35.18.36.27.36.35.35.47.32.59.28.73.21.88.14 1.04.05 1.23-.06 1.23-.16 1.04-.24.86-.32.71-.36.57-.4.45-.42.33-.42.24-.4.16-.36.09-.32.05-.24.02-.16-.01h-8.22v.82h5.84l.01 2.76.02.36-.05.34-.11.31-.17.29-.25.25-.31.24-.38.2-.44.17-.51.15-.58.13-.64.09-.71.07-.77.04-.84.01-1.27-.04-1.07-.14-.9-.2-.73-.25-.59-.3-.45-.33-.34-.34-.25-.34-.16-.33-.1-.3-.04-.25-.02-.2.01-.13v-5.34l.05-.64.13-.54.21-.46.26-.38.3-.32.33-.24.35-.2.35-.14.33-.1.3-.06.26-.04.21-.02.13-.01h5.84l.69-.05.59-.14.5-.21.41-.28.33-.32.27-.35.2-.36.15-.36.1-.35.07-.32.04-.28.02-.21V6.07h2.09l.14.01zm-6.47 14.25l-.23.33-.08.41.08.41.23.33.33.23.41.08.41-.08.33-.23.23-.33.08-.41-.08-.41-.23-.33-.33-.23-.41-.08-.41.08z" fill="currentColor" /></svg>',children:(0,f.jsxs)(b.code,{children:[(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},children:"from"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:" sentence_transformers "}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},children:"import"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:" SentenceTransformer"})]}),"\n",(0,f.jsx)(b.span,{className:"line"}),"\n",(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:"model "}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},children:"="}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:" SentenceTransformer("}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:'"model_id"'}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:")"})]}),"\n",(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:"queries "}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},children:"="}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:" ["}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:'"What\'s the weather like?"'}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:"]"})]}),"\n",(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:"passages "}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},children:"="}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:" ["})]}),"\n",(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:"    'The weather is lovely today.'"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:","})]}),"\n",(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:'    "It\'s so sunny outside!"'}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:","})]}),"\n",(0,f.jsx)(b.span,{className:"line",children:(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:"    'He drove to the stadium.'"})}),"\n",(0,f.jsx)(b.span,{className:"line",children:(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:"]"})}),"\n",(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:"queries_embeddings "}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},children:"="}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:" model.encode_query(queries)"})]}),"\n",(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:"passages_embeddings "}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},children:"="}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:" model.encode_document(passages)"})]}),"\n",(0,f.jsx)(b.span,{className:"line"}),"\n",(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:"similarities "}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#D73A49","--shiki-dark":"#F97583"},children:"="}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:" model.similarity(queries_embeddings, passages_embeddings)"})]}),"\n",(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},children:"print"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#24292E","--shiki-dark":"#E1E4E8"},children:"(similarities)"})]})]})})}),"\n",(0,f.jsxs)(b.h4,{id:"3-using-langchain-",children:["3. Using ",(0,f.jsx)(b.code,{children:"LangChain"})," \uD83E\uDD9C"]}),"\n",(0,f.jsxs)(b.p,{children:["Easily integrate the model into your ",(0,f.jsx)(b.strong,{children:"LangChain"})," applications, such as RAG pipelines."]}),"\n",(0,f.jsx)(b.p,{children:(0,f.jsx)(b.strong,{children:"\uD83D\uDCE6 Installation"})}),"\n",(0,f.jsx)(f.Fragment,{children:(0,f.jsx)(b.pre,{className:"shiki shiki-themes github-light github-dark",style:{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},tabIndex:"0",icon:'<svg viewBox="0 0 24 24"><path d="m 4,4 a 1,1 0 0 0 -0.7070312,0.2929687 1,1 0 0 0 0,1.4140625 L 8.5859375,11 3.2929688,16.292969 a 1,1 0 0 0 0,1.414062 1,1 0 0 0 1.4140624,0 l 5.9999998,-6 a 1.0001,1.0001 0 0 0 0,-1.414062 L 4.7070312,4.2929687 A 1,1 0 0 0 4,4 Z m 8,14 a 1,1 0 0 0 -1,1 1,1 0 0 0 1,1 h 8 a 1,1 0 0 0 1,-1 1,1 0 0 0 -1,-1 z" fill="currentColor" /></svg>',children:(0,f.jsx)(b.code,{children:(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#6F42C1","--shiki-dark":"#B392F0"},children:"pip"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" install"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" langchain=="}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},children:"0.3.27"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" langchain-community=="}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},children:"0.3.29"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" langchain-huggingface=="}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},children:"0.3.1"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" sentence-transformers=="}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},children:"5.1.0"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" faiss-cpu=="}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},children:"1.11.0"})]})})})}),"\n",(0,f.jsx)(b.p,{children:(0,f.jsx)(b.strong,{children:"⚙️ Usage"})}),"\n",(0,f.jsxs)(b.ul,{children:["\n",(0,f.jsxs)(b.li,{children:["See this example: ",(0,f.jsx)(b.a,{href:"usage/langchain_embedding.py",children:(0,f.jsx)(b.code,{children:"usage/langchain_embedding.py"})})]}),"\n"]}),"\n",(0,f.jsxs)(b.h4,{id:"4-using-llamaindex-",children:["4. Using ",(0,f.jsx)(b.code,{children:"LlamaIndex"})," \uD83E\uDD99"]}),"\n",(0,f.jsxs)(b.p,{children:["This is perfect for integrating the model into your ",(0,f.jsx)(b.strong,{children:"LlamaIndex"})," search and retrieval systems."]}),"\n",(0,f.jsx)(b.p,{children:(0,f.jsx)(b.strong,{children:"\uD83D\uDCE6 Installation"})}),"\n",(0,f.jsx)(f.Fragment,{children:(0,f.jsx)(b.pre,{className:"shiki shiki-themes github-light github-dark",style:{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},tabIndex:"0",icon:'<svg viewBox="0 0 24 24"><path d="m 4,4 a 1,1 0 0 0 -0.7070312,0.2929687 1,1 0 0 0 0,1.4140625 L 8.5859375,11 3.2929688,16.292969 a 1,1 0 0 0 0,1.414062 1,1 0 0 0 1.4140624,0 l 5.9999998,-6 a 1.0001,1.0001 0 0 0 0,-1.414062 L 4.7070312,4.2929687 A 1,1 0 0 0 4,4 Z m 8,14 a 1,1 0 0 0 -1,1 1,1 0 0 0 1,1 h 8 a 1,1 0 0 0 1,-1 1,1 0 0 0 -1,-1 z" fill="currentColor" /></svg>',children:(0,f.jsx)(b.code,{children:(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#6F42C1","--shiki-dark":"#B392F0"},children:"pip"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" install"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" llama-index=="}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},children:"0.14.2"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" llama-index-embeddings-huggingface=="}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},children:"0.6.1"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" sentence-transformers=="}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},children:"5.1.0"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" llama-index-vector-stores-faiss=="}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},children:"0.5.1"})]})})})}),"\n",(0,f.jsx)(b.p,{children:(0,f.jsx)(b.strong,{children:"⚙️ Usage"})}),"\n",(0,f.jsxs)(b.ul,{children:["\n",(0,f.jsxs)(b.li,{children:["See this example: ",(0,f.jsx)(b.a,{href:"usage/llamaindex_embedding.py",children:(0,f.jsx)(b.code,{children:"usage/llamaindex_embedding.py"})})]}),"\n"]}),"\n",(0,f.jsx)(b.h2,{id:"-fine-tuning-framework",children:"\uD83D\uDCA1 Fine-tuning Framework"}),"\n",(0,f.jsxs)(b.p,{children:["We provide our novel ",(0,f.jsx)(b.strong,{children:"Collaborative-Discriminative Fine-tuning Framework"}),", designed to overcome the challenges of jointly optimizing different text embedding tasks. By systematically decoupling tasks, we introduce several key innovations to achieve highly efficient unified representation learning."]}),"\n",(0,f.jsx)(b.p,{children:(0,f.jsx)(b.strong,{children:"\uD83C\uDF10 1. Unified & Extensible Data Format"})}),"\n",(0,f.jsx)(b.p,{children:"Our unified data structure seamlessly handles heterogeneous data from IR, STS, classification, and reranking tasks, offering excellent extensibility for incorporating new tasks in the future."}),"\n",(0,f.jsx)(b.p,{children:(0,f.jsx)(b.strong,{children:"\uD83C\uDFAF 2. Task-Differentiated Loss Functions"})}),"\n",(0,f.jsx)(b.p,{children:'We moved beyond a "one-size-fits-all" loss function and designed specialized optimization objectives for different tasks.'}),"\n",(0,f.jsxs)(b.ul,{children:["\n",(0,f.jsxs)(b.li,{children:["\n",(0,f.jsxs)(b.p,{children:[(0,f.jsx)(b.strong,{children:"For IR (Information Retrieval) tasks"}),": We use a powerful InfoNCE contrastive loss that supports multiple positives, hard negatives, and in-batch cross-device negative sampling for superior discriminative ability."]}),"\n"]}),"\n",(0,f.jsxs)(b.li,{children:["\n",(0,f.jsxs)(b.p,{children:[(0,f.jsx)(b.strong,{children:"For STS (Semantic Textual Similarity) tasks"}),": We go beyond simple contrastive learning by adopting ranking-aware objectives (e.g., Pearson loss, KL divergence loss L_RankKL) to directly optimize for ranking consistency."]}),"\n"]}),"\n"]}),"\n",(0,f.jsx)(b.p,{children:(0,f.jsx)(b.strong,{children:"\uD83D\uDD04 3. Dynamic Single-Task Sampling"})}),"\n",(0,f.jsx)(b.p,{children:"To prevent gradient interference from mixed-task batches, we implemented a custom dynamic sampler. It ensures that within a single training iteration, all GPUs process non-overlapping shards of the same dataset, providing the model with a pure and stable gradient signal."}),"\n",(0,f.jsx)("a",{id:"train"}),"\n",(0,f.jsx)(b.h3,{id:"️-how-to-train",children:"\uD83D\uDEE0️ How to Train"}),"\n",(0,f.jsxs)(b.p,{children:["The code for our training framework is located in the ",(0,f.jsx)(b.a,{href:"training/",children:(0,f.jsx)(b.code,{children:"training/"})})," directory."]}),"\n",(0,f.jsx)(b.h4,{id:"1-installation",children:"1. Installation"}),"\n",(0,f.jsx)(b.p,{children:"Clone the repository and install the required dependencies:"}),"\n",(0,f.jsx)(f.Fragment,{children:(0,f.jsx)(b.pre,{className:"shiki shiki-themes github-light github-dark",style:{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},tabIndex:"0",icon:'<svg viewBox="0 0 24 24"><path d="m 4,4 a 1,1 0 0 0 -0.7070312,0.2929687 1,1 0 0 0 0,1.4140625 L 8.5859375,11 3.2929688,16.292969 a 1,1 0 0 0 0,1.414062 1,1 0 0 0 1.4140624,0 l 5.9999998,-6 a 1.0001,1.0001 0 0 0 0,-1.414062 L 4.7070312,4.2929687 A 1,1 0 0 0 4,4 Z m 8,14 a 1,1 0 0 0 -1,1 1,1 0 0 0 1,1 h 8 a 1,1 0 0 0 1,-1 1,1 0 0 0 -1,-1 z" fill="currentColor" /></svg>',children:(0,f.jsxs)(b.code,{children:[(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#6F42C1","--shiki-dark":"#B392F0"},children:"git"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" clone"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" https://github.com/Tencent/CoDiEmb.git"})]}),"\n",(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},children:"cd"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" CoDiEmb"})]}),"\n",(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#6F42C1","--shiki-dark":"#B392F0"},children:"pip"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" install"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},children:" -r"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" requirements.txt"})]})]})})}),"\n",(0,f.jsx)(b.h4,{id:"2-training",children:"2. Training"}),"\n",(0,f.jsx)(f.Fragment,{children:(0,f.jsx)(b.pre,{className:"shiki shiki-themes github-light github-dark",style:{"--shiki-light":"#24292e","--shiki-dark":"#e1e4e8","--shiki-light-bg":"#fff","--shiki-dark-bg":"#24292e"},tabIndex:"0",icon:'<svg viewBox="0 0 24 24"><path d="m 4,4 a 1,1 0 0 0 -0.7070312,0.2929687 1,1 0 0 0 0,1.4140625 L 8.5859375,11 3.2929688,16.292969 a 1,1 0 0 0 0,1.414062 1,1 0 0 0 1.4140624,0 l 5.9999998,-6 a 1.0001,1.0001 0 0 0 0,-1.414062 L 4.7070312,4.2929687 A 1,1 0 0 0 4,4 Z m 8,14 a 1,1 0 0 0 -1,1 1,1 0 0 0 1,1 h 8 a 1,1 0 0 0 1,-1 1,1 0 0 0 -1,-1 z" fill="currentColor" /></svg>',children:(0,f.jsxs)(b.code,{children:[(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#005CC5","--shiki-dark":"#79B8FF"},children:"cd"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" scripts"})]}),"\n",(0,f.jsxs)(b.span,{className:"line",children:[(0,f.jsx)(b.span,{style:{"--shiki-light":"#6F42C1","--shiki-dark":"#B392F0"},children:"bash"}),(0,f.jsx)(b.span,{style:{"--shiki-light":"#032F62","--shiki-dark":"#9ECBFF"},children:" train_youtuemb.sh"})]})]})})}),"\n",(0,f.jsx)(b.h4,{id:"3-evaluation",children:"3. Evaluation"}),"\n",(0,f.jsxs)(b.p,{children:["The code for reproducing the following results is available in ",(0,f.jsx)(b.code,{children:"evaluation/"}),"."]}),"\n",(0,f.jsx)(b.h2,{id:"-cmteb",children:"\uD83D\uDCCA CMTEB"}),"\n",(0,f.jsx)(b.p,{children:"Youtu-Embedding demonstrates superior performance across all seven task categories on the CMTEB benchmark and achieves the highest overall average score. We present the results of the latest version of the model as follows:"}),"\n",(0,f.jsxs)(b.table,{children:[(0,f.jsx)(b.thead,{children:(0,f.jsxs)(b.tr,{children:[(0,f.jsx)(b.th,{style:{textAlign:"left"},children:"Model"}),(0,f.jsx)(b.th,{style:{textAlign:"left"},children:"Mean(Task)"}),(0,f.jsx)(b.th,{style:{textAlign:"left"},children:"Mean(Type)"}),(0,f.jsx)(b.th,{style:{textAlign:"center"},children:"Class."}),(0,f.jsx)(b.th,{style:{textAlign:"center"},children:"Clust."}),(0,f.jsx)(b.th,{style:{textAlign:"center"},children:"Pair Class."}),(0,f.jsx)(b.th,{style:{textAlign:"center"},children:"Rerank."}),(0,f.jsx)(b.th,{style:{textAlign:"center"},children:"Retr."}),(0,f.jsx)(b.th,{style:{textAlign:"center"},children:"STS"})]})}),(0,f.jsxs)(b.tbody,{children:[(0,f.jsxs)(b.tr,{children:[(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"gte-Qwen2-1.5B-instruct"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"67.12"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"67.79"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"72.53"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"54.61"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"79.50"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"68.21"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"71.86"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"60.05"})]}),(0,f.jsxs)(b.tr,{children:[(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"bge-multilingual-gemma2"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"67.64"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"68.52"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"75.31"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"59.30"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"86.67"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"68.28"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"73.73"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"55.19"})]}),(0,f.jsxs)(b.tr,{children:[(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"ritrieve_zh_v1"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"72.71"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"73.85"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"76.88"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"66.50"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"85.98"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"72.86"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"76.97"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"63.92"})]}),(0,f.jsxs)(b.tr,{children:[(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"Qwen3-Embedding-4B"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"72.27"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"73.51"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"75.46"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"77.89"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"83.34"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"66.05"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"77.03"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"61.26"})]}),(0,f.jsxs)(b.tr,{children:[(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"Qwen3-Embedding-8B"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"73.84"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"75.00"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"76.97"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"80.08"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"84.23"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"66.99"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"78.21"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"63.53"})]}),(0,f.jsxs)(b.tr,{children:[(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"Conan-embedding-v2"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"74.24"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"75.99"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"76.47"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"68.84"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"92.44"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"74.41"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"78.31"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"65.48"})]}),(0,f.jsxs)(b.tr,{children:[(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"Seed1.6-embedding"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"75.63"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"76.68"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"77.98"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"73.11"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"88.71"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"71.65"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"79.69"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"68.94"})]}),(0,f.jsxs)(b.tr,{children:[(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"QZhou-Embedding"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"76.99"}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:"78.58"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"79.99"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"70.91"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"95.07"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"74.85"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"78.80"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"71.89"})]}),(0,f.jsxs)(b.tr,{children:[(0,f.jsx)(b.td,{style:{textAlign:"left"},children:(0,f.jsx)(b.strong,{children:"Youtu-Embedding-V1-0917"})}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:(0,f.jsx)(b.strong,{children:"77.60"})}),(0,f.jsx)(b.td,{style:{textAlign:"left"},children:(0,f.jsx)(b.strong,{children:"78.85"})}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"78.04"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"79.67"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"89.69"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"73.85"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"80.95"}),(0,f.jsx)(b.td,{style:{textAlign:"center"},children:"70.91"})]})]})]}),"\n",(0,f.jsx)(b.h2,{id:"-citation",children:"\uD83C\uDF89 Citation"}),"\n",(0,f.jsx)(b.p,{children:"If you find our work useful in your research, please consider citing our paper:"})]})}function u(a={}){let{wrapper:b}=a.components||{};return b?(0,f.jsx)(b,{...a,children:(0,f.jsx)(t,{...a})}):t(a)}let v=c(82184).E_.docs([{info:{path:"index.mdx",fullPath:"content/docs/index.mdx"},data:e},{info:{path:"test.mdx",fullPath:"content/docs/test.mdx"},data:d}],[]),w=(0,c(60570).wG)({baseUrl:"/",source:v.toFumadocsSource()});async function x(a){let b=await a.data.getText("processed");return`# ${a.data.title} (${a.url})

${b}`}}};