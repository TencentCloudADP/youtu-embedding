---
title: Quickly Start Inference
description: Get started with Youtu-Embedding in minutes
---

You can generate embeddings in two ways: via our official API for ease of use or by running the model locally for full control.

### Option 1: â˜ï¸ Using the Official API
**ğŸ“¦ Install the SDK** 

```bash
pip install --upgrade tencentcloud-sdk-python
```
- **API Guide**: For details on authentication and endpoints, see the [Tencent Cloud API Documentation](https://cloud.tencent.com/document/product/1772/115343).
- **SDK Reference**: For more on the SDK, refer to the [SDK Installation Guide](https://cloud.tencent.com/document/sdk).

**âš™ï¸ Usage**

- Please see the script in [`usage/tencent_cloud_api.py`](usage/tencent_cloud_api.py).

### Option 2: ğŸ’» Locally with Self-Hosted Inference
Running the model on your own machine gives you full control, making it perfect for offline use, customization, or when data privacy is a priority. Here are a few popular ways to get started.

#### 1. Using the Custom `LLMEmbeddingModel` Class
For a more specialized implementation or to see our direct wrapper, you can use the `LLMEmbeddingModel` class.

- See the complete example script here: [`usage/infer_llm_embedding.py`](usage/infer_llm_embedding.py).

#### 2. Using `sentence-transformers`
**ğŸ“¦ Installation**
```bash
pip install sentence-transformers==5.1.0
```
**âš™ï¸ Usage**
```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("model_id")
queries = ["What's the weather like?"]
passages = [
    'The weather is lovely today.',
    "It's so sunny outside!",
    'He drove to the stadium.'
]
queries_embeddings = model.encode_query(queries)
passages_embeddings = model.encode_document(passages)

similarities = model.similarity(queries_embeddings, passages_embeddings)
print(similarities)
```

#### 3. Using `LangChain` ğŸ¦œ
Easily integrate the model into your **LangChain** applications, such as RAG pipelines.

**ğŸ“¦ Installation**

```bash
pip install langchain==0.3.27 langchain-community==0.3.29 langchain-huggingface==0.3.1 sentence-transformers==5.1.0 faiss-cpu==1.11.0
```

**âš™ï¸ Usage**

- See this example: [`usage/langchain_embedding.py`](usage/langchain_embedding.py)

#### 4. Using `LlamaIndex` ğŸ¦™
This is perfect for integrating the model into your **LlamaIndex** search and retrieval systems.

**ğŸ“¦ Installation**

```bash
pip install llama-index==0.14.2 llama-index-embeddings-huggingface==0.6.1 sentence-transformers==5.1.0 llama-index-vector-stores-faiss==0.5.1
```

**âš™ï¸ Usage**

- See this example: [`usage/llamaindex_embedding.py`](usage/llamaindex_embedding.py)
